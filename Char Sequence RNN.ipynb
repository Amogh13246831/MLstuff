{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Char-Sequence RNN</h1>\n",
    "\n",
    "Taken from https://gist.github.com/karpathy/d4dee566867f8291f086"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a test sentence for the sequence generation RNN\n",
      "\n",
      "\n",
      "['c', 'R', 'e', 'o', 'N', 's', 'a', 'q', 'u', 'g', '\\n', 't', 'r', 'f', 'h', 'i', 'n', ' ']\n",
      "57\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "data = open('test.txt', 'r').read()\n",
    "chars = list(set(data))\n",
    "data_size, vocab_size = len(data), len(chars)\n",
    "print(data, chars, data_size, vocab_size, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'c': 0, 'R': 1, 'e': 2, 'o': 3, 'N': 4, 's': 5, 'a': 6, 'q': 7, 'u': 8, 'g': 9, '\\n': 10, 't': 11, 'r': 12, 'f': 13, 'h': 14, 'i': 15, 'n': 16, ' ': 17}\n",
      "{0: 'c', 1: 'R', 2: 'e', 3: 'o', 4: 'N', 5: 's', 6: 'a', 7: 'q', 8: 'u', 9: 'g', 10: '\\n', 11: 't', 12: 'r', 13: 'f', 14: 'h', 15: 'i', 16: 'n', 17: ' '}\n"
     ]
    }
   ],
   "source": [
    "char_to_ix = {ch:i for i, ch in enumerate(chars)}\n",
    "ix_to_char = {i:ch for i, ch in enumerate(chars)}\n",
    "print(char_to_ix, ix_to_char, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "hidden_size = 100\n",
    "seq_length = 25\n",
    "learning_rate = 1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.16216257e-04  5.20287798e-05 -6.34111563e-03  1.27913264e-03\n",
      "  -8.42735376e-03  2.41981070e-02  1.71583785e-03 -3.50337489e-03\n",
      "  -1.75061287e-03 -4.20895098e-03  3.74193687e-04 -6.03903281e-03\n",
      "  -2.69658092e-03 -3.66905793e-04  1.07542928e-02  1.47778949e-02\n",
      "   1.05777283e-02 -6.18650724e-03]\n",
      " [ 1.63251050e-02 -1.50234832e-02  8.28528091e-03  9.13632378e-03\n",
      "   1.81584744e-02  6.33851867e-03  1.76542327e-03  1.42450387e-02\n",
      "  -9.74520002e-03  2.90698593e-03  1.32273842e-02 -7.31530130e-03\n",
      "  -1.30914532e-02  7.45783958e-03  7.05801828e-03  7.49372112e-03\n",
      "  -7.35677305e-03  2.33519441e-02]]\n",
      "\n",
      "[[ 0.00510032  0.01343263  0.01333247  0.00411951 -0.00256134 -0.01756038\n",
      "   0.00923666 -0.00029012 -0.01030918  0.00785071 -0.00720719  0.00432183\n",
      "   0.016622    0.00944487 -0.00092601  0.0031886  -0.00171729  0.00197577\n",
      "   0.00083118  0.0033164  -0.00383565  0.00415565 -0.01085973 -0.00190067\n",
      "  -0.00415697  0.00759467  0.00571631  0.0078816  -0.01478265  0.00418319\n",
      "  -0.00029124  0.00508052 -0.01481809 -0.00079623  0.01377059 -0.00257377\n",
      "  -0.00305025 -0.00601878  0.00746666  0.00282639 -0.00842506 -0.00025273\n",
      "   0.00312572  0.00822012  0.00484661 -0.00339536  0.00923561 -0.0002541\n",
      "   0.00693666  0.00828381  0.01362287 -0.01331707 -0.01068839 -0.00313045\n",
      "   0.00766921  0.00254119 -0.004572    0.00532226  0.00275563  0.01543769\n",
      "  -0.00812368  0.00127603  0.00371891 -0.00931533 -0.00877008  0.00274387\n",
      "  -0.00207576 -0.01581227  0.01372554  0.00993121 -0.0054358   0.00864902\n",
      "   0.01383665 -0.02631217 -0.00268873  0.00821423 -0.01202537 -0.00439533\n",
      "  -0.00079633  0.01934541  0.02248976 -0.00889921 -0.01212661  0.01220304\n",
      "  -0.00445211  0.01057412  0.00020616  0.00373182 -0.0029783  -0.00829275\n",
      "   0.00375402 -0.00121546 -0.0227787  -0.01821377  0.0090483   0.00240478\n",
      "   0.00031619 -0.01280678 -0.00360814  0.00739676]\n",
      " [-0.00139018 -0.01213658  0.00247934 -0.01481979 -0.01178558  0.00079721\n",
      "  -0.00667306 -0.00972465  0.00804102  0.02144581 -0.00158676  0.00099923\n",
      "  -0.00331118 -0.01294835 -0.00588111  0.00263595 -0.00769815  0.00860858\n",
      "   0.02804503 -0.0070218  -0.00301401  0.00134559  0.01205301 -0.01763835\n",
      "   0.00238636  0.0089973   0.01275923  0.00011816 -0.00805259 -0.00292234\n",
      "   0.00231388  0.01163311  0.00204136 -0.00153575 -0.00357019 -0.00440803\n",
      "   0.00782087  0.01274995 -0.00257817  0.00203471 -0.00506752  0.01039272\n",
      "   0.00574736  0.00780271 -0.00805476 -0.01001727  0.02081292  0.00503866\n",
      "  -0.00280554  0.01584033  0.01830844 -0.00360881  0.01230271  0.00694335\n",
      "  -0.00266673 -0.0039682  -0.01086469  0.00542726 -0.01001734  0.00455016\n",
      "  -0.00495755  0.00224737  0.00104628 -0.00199026 -0.00817729  0.00800807\n",
      "  -0.01100624  0.01447274  0.01378344  0.00313398  0.0026271  -0.0082233\n",
      "  -0.00870113 -0.01075977 -0.003472   -0.0087137  -0.00682104  0.00336799\n",
      "   0.01110798  0.00410354 -0.01666099  0.00543737  0.01053491 -0.00740873\n",
      "   0.00696674 -0.01943071 -0.00411302 -0.00057721 -0.00270623 -0.00551538\n",
      "   0.0061646  -0.00410641  0.0066982  -0.01030499 -0.00272321  0.00212148\n",
      "  -0.00189642  0.01362225  0.00759031 -0.00685497]]\n",
      "\n",
      "[[-4.71823036e-03 -8.16111016e-03  3.58609838e-03 -9.89851965e-03\n",
      "   7.78857985e-03  5.34790477e-04  2.96301145e-03  9.69077677e-03\n",
      "   1.00892241e-03  7.14078644e-03  1.48900420e-02 -2.54308800e-04\n",
      "   7.55759424e-03  5.91275823e-03  1.85451802e-02  1.49637480e-03\n",
      "  -2.34113230e-03  9.52637033e-03 -5.37521998e-03  9.83443415e-03\n",
      "   1.46819701e-02  1.12155740e-03 -1.01019846e-02  1.13593263e-02\n",
      "   2.92069771e-04  1.31980833e-02 -1.42683638e-04 -1.33883320e-04\n",
      "  -9.62350739e-03 -6.76397371e-03  1.11648735e-02  2.86715062e-03\n",
      "   6.88352330e-03 -1.13881867e-02 -8.28875863e-03 -4.17834086e-03\n",
      "  -1.44486107e-02 -1.13587842e-02 -4.92270735e-03  4.76670407e-03\n",
      "  -9.70639473e-03 -5.06050165e-03 -7.19335004e-04  7.36276692e-03\n",
      "   7.70895096e-03  1.76507980e-02 -1.02053066e-02  3.61297426e-04\n",
      "  -6.74753513e-03  1.21944935e-02 -1.07981067e-02  1.03986119e-03\n",
      "   1.43239252e-02 -1.22543499e-02  2.43831849e-03  1.87813259e-03\n",
      "  -2.98521978e-03 -1.67495806e-02 -8.41704792e-03 -1.36043762e-02\n",
      "  -5.40877977e-03  5.06479109e-03  2.21987412e-02 -2.01579005e-02\n",
      "  -5.13448461e-03 -3.59946327e-03 -8.27615712e-03  3.57828152e-03\n",
      "  -4.81421398e-03 -1.78516151e-02  1.58639024e-02  5.92621432e-03\n",
      "   6.51687253e-03  1.88492785e-03 -5.41678298e-03  1.04674207e-02\n",
      "  -1.30129712e-02 -1.86156758e-02  5.71122474e-03 -1.35060706e-02\n",
      "   7.18029841e-03 -1.80149945e-02  3.63717528e-03 -6.47301780e-03\n",
      "   1.18442708e-02 -2.33437152e-03  1.59540067e-02  1.42030126e-02\n",
      "  -6.34515512e-03 -1.75469830e-02 -2.26727939e-02  9.91632076e-03\n",
      "   2.71300949e-03 -8.76511017e-03  1.44221202e-03  1.04189612e-02\n",
      "  -1.09541733e-02  4.98296000e-03 -1.04963675e-02  9.81847641e-04]\n",
      " [-1.50775679e-02 -7.16200873e-03 -1.51427100e-02 -1.50806883e-04\n",
      "   3.85690760e-04 -1.97552583e-03  1.82766195e-02  3.31125002e-04\n",
      "  -9.85159355e-03  5.23975309e-03 -9.86464360e-03  7.08977573e-03\n",
      "   8.98286491e-03  8.54934372e-03  1.52819471e-03  7.14387200e-03\n",
      "  -1.54497172e-02 -4.80275750e-03  5.52299055e-03  4.01913894e-04\n",
      "   1.98448039e-02  4.23364856e-03  2.71741502e-03 -9.05421660e-03\n",
      "   1.45880001e-02  1.19058826e-02  1.27709220e-02  2.00219417e-02\n",
      "   4.08456797e-03  2.63517243e-03 -2.81854419e-03 -1.96495126e-03\n",
      "   1.22453132e-03 -2.11514603e-02  5.15588415e-03 -4.10782947e-03\n",
      "   7.62816731e-03 -5.38582219e-03  1.47842419e-02 -2.27843578e-03\n",
      "   5.34741517e-03 -9.47888837e-03 -8.81461616e-04 -8.76340224e-03\n",
      "   6.99776371e-03  9.27019134e-03 -3.60372970e-03  3.07791904e-02\n",
      "   8.91058039e-03 -1.35847011e-03 -1.41129404e-02  1.70582738e-02\n",
      "  -5.27551802e-03  8.98507913e-04  1.75192405e-02 -3.60918974e-03\n",
      "  -6.57428501e-03  2.09490871e-03 -1.94793245e-02 -3.17535307e-03\n",
      "  -3.43860397e-02 -1.83758429e-02  2.58054863e-02  6.84926815e-03\n",
      "   7.44763612e-03  6.75008041e-03  1.25472119e-02  1.18672358e-02\n",
      "  -1.77547472e-06 -2.08283049e-02 -1.01935144e-02 -1.22635819e-03\n",
      "  -2.06188179e-02  2.17017950e-02  5.84983640e-03  2.82897238e-03\n",
      "  -2.39164955e-03  2.91216480e-03  1.13862405e-02  2.48914972e-03\n",
      "  -1.00456504e-02 -1.98936439e-02  1.48534824e-02  4.62958704e-03\n",
      "   1.09294696e-02  9.98392024e-03  2.07075612e-03 -1.37871296e-02\n",
      "   1.09550394e-02  6.98768556e-05  5.77229072e-04  1.96471243e-02\n",
      "  -1.05892782e-02 -5.84513367e-03 -2.08679623e-04 -2.10590986e-03\n",
      "  -6.52062258e-03 -5.61426066e-03  9.56991063e-03  6.25692551e-03]]\n",
      "\n",
      "[[0.]\n",
      " [0.]]\n",
      "\n",
      "[[0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "# model parameters\n",
    "Wxh = np.random.randn(hidden_size, vocab_size) * 0.01  # 100x28\n",
    "Whh = np.random.randn(hidden_size, hidden_size) * 0.01  # 100x100\n",
    "Why = np.random.randn(vocab_size, hidden_size) * 0.01  # 28x100\n",
    "bh = np.zeros((hidden_size, 1))\n",
    "by = np.zeros((vocab_size, 1))\n",
    "print(Wxh[:2,], Whh[:2,], Why[:2,], bh[:2], by[:2], sep=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "def loss_func(inputs, targets, hprev):\n",
    "    \n",
    "    xs, hs, ys, ps = {}, {}, {}, {}\n",
    "    hs[-1] = np.copy(hprev)\n",
    "    loss = 0\n",
    "    \n",
    "    # forward pass\n",
    "    for t in range(len(inputs)):\n",
    "        xs[t] = np.zeros((vocab_size, 1))\n",
    "        xs[t][inputs[t]] = 1 # one-hot encoding\n",
    "        hs[t] = np.tanh(np.dot(Wxh, xs[t]) + np.dot(Whh, hs[t-1]) + bh) # inputs and prev. state for forward pass\n",
    "        ys[t] = np.dot(Why, hs[t]) + by # output layer pre-softmax\n",
    "        ps[t] = np.exp(ys[t]) / np.sum(np.exp(ys[t])) # softmax\n",
    "        loss += -np.log(ps[t][targets[t], 0]) # cross-entropy loss with target\n",
    "    \n",
    "    #backward pass\n",
    "    dWxh, dWhh, dWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)\n",
    "    dbh, dby = np.zeros_like(bh), np.zeros_like(by)\n",
    "    dhnext = np.zeros_like(hs[0])\n",
    "    for t in reversed(range(len(inputs))):\n",
    "        dy = np.copy(ps[t])\n",
    "        dy[targets[t]] -= 1 # backprop into y: dL/df = -log(f) - 1, -log(f) is in ps[t] - Analytic Gradient\n",
    "        dWhy += np.dot(dy, hs[t].T) # output error * hidden activations\n",
    "        dby += dy\n",
    "        dh = np.dot(Why.T, dy) + dhnext # backprop into h (though topology and time), summation dk*wkj\n",
    "        dhraw = (1 - hs[t]*hs[t]) * dh # backprop through tanh nonlinearity\n",
    "        dbh += dhraw\n",
    "        dWxh += np.dot(dhraw, xs[t].T)\n",
    "        dWhh += np.dot(dhraw, hs[t-1].T)\n",
    "        dhnext = np.dot(Whh.T, dhraw)\n",
    "        \n",
    "    for dparam in [dWxh, dWhh, dWhy, dbh, dby]:\n",
    "        np.clip(dparam, -5, 5, out=dparam) # stop exploding gradients\n",
    "    \n",
    "    return loss, dWxh, dWhh, dWhy, dbh, dby, hs[len(inputs)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample a sequence of n integers\n",
    "def sample(h, seed_ix, n): # h is memory state, seed_ix is seed letter for first time step\n",
    "    \n",
    "    x = np.zeros((vocab_size, 1))\n",
    "    x[seed_ix] = 1 # one-hot encoding\n",
    "    ixes = []\n",
    "    \n",
    "    for t in range(n):\n",
    "        h = np.tanh(np.dot(Wxh, x) + np.dot(Whh, h) + bh)\n",
    "        y = np.dot(Why, h) + by\n",
    "        p = np.exp(y) / np.sum(np.exp(y)) # forward pass done\n",
    "        ix = np.random.choice(range(vocab_size), p=p.ravel())\n",
    "        x = np.zeros((vocab_size, 1))\n",
    "        x[ix] = 1;\n",
    "        ixes.append(ix)\n",
    "        \n",
    "    return ixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      " otNuqcr\n",
      "qcgfcg fqcanuahugesuhRegcn\n",
      "sneNoRcgsRanog\n",
      "iirs\n",
      "u sonhoahReuuNnNrutnti e\n",
      "rieNratuuRssneicheofiiqqhoe fqf\n",
      "rfgoa\n",
      "fsteotuRoqsfR\n",
      "ieitaceccffocsofR\n",
      " httacNausrffocitgeioRRcr RfNRae agranrfRrtuhttcNa \n",
      "----\n",
      "Iteration 0:\tloss: 72.25929756886642\n",
      "Iteration 100:\tloss: 71.88596943285263\n",
      "Iteration 200:\tloss: 68.67430557621368\n",
      "Iteration 300:\tloss: 63.52956640390451\n",
      "Iteration 400:\tloss: 58.15387411103397\n",
      "----\n",
      " his isentenct for the sequence generationce for the sequeece gengenerationce sentence foneq foncence for the sequence sequence generationse so fontats n the gequence generationsaesense for the sequenc \n",
      "----\n",
      "Iteration 500:\tloss: 52.9408630927503\n",
      "Iteration 600:\tloss: 48.084847637686906\n",
      "Iteration 700:\tloss: 43.632835977979376\n",
      "Iteration 800:\tloss: 39.5724752519512\n",
      "Iteration 900:\tloss: 35.87926841815128\n",
      "----\n",
      " his is a test sentence for the sequence senuence generahiontence for the sequence generationce for the sequence ge gence generationeence for the sequence sequence generationce for the sequence generat \n",
      "----\n",
      "Iteration 1000:\tloss: 32.52475274965582\n",
      "Iteration 1100:\tloss: 29.480389963295284\n",
      "Iteration 1200:\tloss: 26.718970715434875\n",
      "Iteration 1300:\tloss: 24.215100135282263\n",
      "Iteration 1400:\tloss: 21.94532774784848\n",
      "----\n",
      " his is a test sentence for the sequenceqerationtence for the sequence generationtence for the sequence generationtence for the sequence generationce for the sequence generationtence for the ceneration \n",
      "----\n",
      "Iteration 1500:\tloss: 19.88812413122837\n",
      "Iteration 1600:\tloss: 18.023800920337205\n",
      "Iteration 1700:\tloss: 16.334425376433384\n",
      "Iteration 1800:\tloss: 14.80371255343027\n",
      "Iteration 1900:\tloss: 13.416873159131347\n",
      "----\n",
      " his is a test sentence for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generationtence for the sequence generationtence for the sequence gene \n",
      "----\n",
      "Iteration 2000:\tloss: 12.160468111157737\n",
      "Iteration 2100:\tloss: 11.02228930932064\n",
      "Iteration 2200:\tloss: 9.991253094621598\n",
      "Iteration 2300:\tloss: 9.057301404062937\n",
      "Iteration 2400:\tloss: 8.211310265019602\n",
      "----\n",
      " his is a test sentence for the sequence generationtence for the sequence generationtence for the sequence generationce for the sequence generationtence for the sequence generationtence for the sequenc \n",
      "----\n",
      "Iteration 2500:\tloss: 7.44500557243406\n",
      "Iteration 2600:\tloss: 6.750885857573502\n",
      "Iteration 2700:\tloss: 6.122151623748608\n",
      "Iteration 2800:\tloss: 5.5526407844100305\n",
      "Iteration 2900:\tloss: 5.036769748485504\n",
      "----\n",
      " his is a test sentence for the sequence generationce for the sequence generationce for the sequence generationtence for the sequence generationfence for the sequence generationtence for the sequence g \n",
      "----\n",
      "Iteration 3000:\tloss: 4.569479726295821\n",
      "Iteration 3100:\tloss: 4.14618785518954\n",
      "Iteration 3200:\tloss: 3.7627427611932274\n",
      "Iteration 3300:\tloss: 3.4153841879616103\n",
      "Iteration 3400:\tloss: 3.1007063430517627\n",
      "----\n",
      " his is a test sentence for the sequence generationsence for the sequence generationce for the sequence generationtence for the sequence generationtence for the sequence generationce for the sequence g \n",
      "----\n",
      "Iteration 3500:\tloss: 2.8156246341912072\n",
      "Iteration 3600:\tloss: 2.55734549241773\n",
      "Iteration 3700:\tloss: 2.3233390030406453\n",
      "Iteration 3800:\tloss: 2.1113140886260364\n",
      "Iteration 3900:\tloss: 1.9191960103404233\n",
      "----\n",
      " his is a test sentence for the sequence generationtence for the sequence generationtence for the sequence generationce for the sequence generationce for the sequence generationce for the sequence gene \n",
      "----\n",
      "Iteration 4000:\tloss: 1.745105974730863\n",
      "Iteration 4100:\tloss: 1.5873426521479554\n",
      "Iteration 4200:\tloss: 1.4443654304389812\n",
      "Iteration 4300:\tloss: 1.3147792433212007\n",
      "Iteration 4400:\tloss: 1.1973208271687312\n",
      "----\n",
      " his is a test sentence for thensequence e test sentence for the sequence generationtence for the sequence generationtence for the sequence generationce for the sequence generationtence for the sequenc \n",
      "----\n",
      "Iteration 4500:\tloss: 1.0908462730140476\n",
      "Iteration 4600:\tloss: 0.9943197525457357\n",
      "Iteration 4700:\tloss: 0.9068033078934542\n",
      "Iteration 4800:\tloss: 0.8274476051033146\n",
      "Iteration 4900:\tloss: 0.7554835604759137\n",
      "----\n",
      " his is a test sentence for the sequence generationce for the sequence generationce for the sequencenerationce for the sequence generationeence for the sequence generationtence sence for the sequence g \n",
      "----\n",
      "Iteration 5000:\tloss: 0.6902147574130129\n",
      "Iteration 5100:\tloss: 0.6310105791465715\n",
      "Iteration 5200:\tloss: 0.5772999897562154\n",
      "Iteration 5300:\tloss: 0.5285659022689828\n",
      "Iteration 5400:\tloss: 0.48434007842794574\n",
      "----\n",
      " his is a test sentence for the sequence generationtence for the sequence generationce for the sequence generationtence for the sequence generationce for the sequence generationsence for the sequence g \n",
      "----\n",
      "Iteration 5500:\tloss: 0.4441985099619407\n",
      "Iteration 5600:\tloss: 0.40775723593394375\n",
      "Iteration 5700:\tloss: 0.37466855503630564\n",
      "Iteration 5800:\tloss: 0.3446175955818428\n",
      "Iteration 5900:\tloss: 0.3173192094539441\n",
      "----\n",
      " his is a test sentence for the sequence generationtence for the sequence e test sentence for the sequence generationce for the sequence generationtence for the sequence generationce for the sequence g \n",
      "----\n",
      "Iteration 6000:\tloss: 0.2925151594677145\n",
      "Iteration 6100:\tloss: 0.2699715724973807\n",
      "Iteration 6200:\tloss: 0.24947663338085993\n",
      "Iteration 6300:\tloss: 0.23083849705766843\n",
      "Iteration 6400:\tloss: 0.21388339866555342\n",
      "----\n",
      " his is a test sentence for the sequence generationtence for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generationtence for the sequence gene \n",
      "----\n",
      "Iteration 6500:\tloss: 0.19845394343934056\n",
      "Iteration 6600:\tloss: 0.18440756022137675\n",
      "Iteration 6700:\tloss: 0.1716151041492304\n",
      "Iteration 6800:\tloss: 0.15995959548272337\n",
      "Iteration 6900:\tloss: 0.14933508232308756\n",
      "----\n",
      " his is a test sentence for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generationtence for the sequence generationce for the sequence generat \n",
      "----\n",
      "Iteration 7000:\tloss: 0.13964561493856298\n",
      "Iteration 7100:\tloss: 0.1308043186548615\n",
      "Iteration 7200:\tloss: 0.12273255160595363\n",
      "Iteration 7300:\tloss: 0.11535913445929671\n",
      "Iteration 7400:\tloss: 0.10861964243216995\n",
      "----\n",
      " his is a test sentence for the sequence generationsence for the sequence generationtence for the sequence generationtence for the sequence generationce for the sequence generationtence for the sequenc \n",
      "----\n",
      "Iteration 7500:\tloss: 0.10245575462571434\n",
      "Iteration 7600:\tloss: 0.0968146595072336\n",
      "Iteration 7700:\tloss: 0.09164851640217359\n",
      "Iteration 7800:\tloss: 0.08691397140113981\n",
      "Iteration 7900:\tloss: 0.08257172390712753\n",
      "----\n",
      " his is a test sentence for the sequence generationce for the sequence generationtence for the sequence generationce for the sequence generationce for the sequence generationeence for the sequence gene \n",
      "----\n",
      "Iteration 8000:\tloss: 0.07858613862559662\n",
      "Iteration 8100:\tloss: 0.07492489751280129\n",
      "Iteration 8200:\tloss: 0.07155868667865395\n",
      "Iteration 8300:\tloss: 0.06846091399969435\n",
      "Iteration 8400:\tloss: 0.06560745392873894\n",
      "----\n",
      " his is a test sentence for the sequence generationcentence for the sequence generationtence for the sequence generationce for the sequence generationce for the sequence generationtence for the sequenc \n",
      "----\n",
      "Iteration 8500:\tloss: 0.06297641657813506\n",
      "Iteration 8600:\tloss: 0.06054793859905085\n",
      "Iteration 8700:\tloss: 0.05830399371272901\n",
      "Iteration 8800:\tloss: 0.05622822100596559\n",
      "Iteration 8900:\tloss: 0.05430576930836775\n",
      "----\n",
      " his is a test sentence for the sequence generationce for the sequence generationce for the sequence generationtence for the sequence generationce for the sequence generationce for the sequence generat \n",
      "----\n",
      "Iteration 9000:\tloss: 0.052523156140143794\n",
      "Iteration 9100:\tloss: 0.05086813986660033\n",
      "Iteration 9200:\tloss: 0.04932960382529467\n",
      "Iteration 9300:\tloss: 0.04789745130762073\n",
      "Iteration 9400:\tloss: 0.04656251038084334\n",
      "----\n",
      " his is a test sentence for the sequence generationtence for the sequence generationce for the sequence generationce for the sequence generationtence for the sequence generationeence for the sequence g \n",
      "----\n",
      "Iteration 9500:\tloss: 0.04531644763082813\n",
      "Iteration 9600:\tloss: 0.04415168999111931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9700:\tloss: 0.04306135390152063\n",
      "Iteration 9800:\tloss: 0.04203918110970889\n",
      "Iteration 9900:\tloss: 0.041079480493332696\n",
      "----\n",
      " his is a test sentence for the sequence generationttnce for the sequence generationtence for the sequence generationce for the sequence generationce for the sequence generationtence for the sequence g \n",
      "----\n",
      "Iteration 10000:\tloss: 0.04017707533810542\n",
      "Iteration 10100:\tloss: 0.039327255560133445\n",
      "Iteration 10200:\tloss: 0.038525734408608764\n",
      "Iteration 10300:\tloss: 0.037768609228471764\n",
      "Iteration 10400:\tloss: 0.03705232590212199\n",
      "----\n",
      " his is a test sentence for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generationtence for the sequence generat \n",
      "----\n",
      "Iteration 10500:\tloss: 0.03637364662507275\n",
      "Iteration 10600:\tloss: 0.0357296207029449\n",
      "Iteration 10700:\tloss: 0.035117558086669186\n",
      "Iteration 10800:\tloss: 0.034535005389481385\n",
      "Iteration 10900:\tloss: 0.03397972415349303\n",
      "----\n",
      " his is a test sentence for the sequence generationce for the sequence generationce for the sequence generation e for the sequence generationce for the sequence generationce for the sequence generation \n",
      "----\n",
      "Iteration 11000:\tloss: 0.03344967115551938\n",
      "Iteration 11100:\tloss: 0.03294298056163377\n",
      "Iteration 11200:\tloss: 0.032457947757774684\n",
      "Iteration 11300:\tloss: 0.031993014699807615\n",
      "Iteration 11400:\tloss: 0.03154675664088653\n",
      "----\n",
      " his is a test sentence for the sequence generation ence for the sequence generationce for the sequence generationce for the sequence generationtence for the sequence generationce for the sequence gene \n",
      "----\n",
      "Iteration 11500:\tloss: 0.031117870106905046\n",
      "Iteration 11600:\tloss: 0.030705162002405032\n",
      "Iteration 11700:\tloss: 0.030307539739659956\n",
      "Iteration 11800:\tloss: 0.029924002292914014\n",
      "Iteration 11900:\tloss: 0.02955363208808966\n",
      "----\n",
      " his is a test sentence for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generation \n",
      "----\n",
      "Iteration 12000:\tloss: 0.02919558764584149\n",
      "Iteration 12100:\tloss: 0.02884909690280091\n",
      "Iteration 12200:\tloss: 0.0285134511423891\n",
      "Iteration 12300:\tloss: 0.028187999472815566\n",
      "Iteration 12400:\tloss: 0.02787214379593505\n",
      "----\n",
      " his is a test sentence for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generationtence for the sequence generationce for the sequence generat \n",
      "----\n",
      "Iteration 12500:\tloss: 0.02756533421655625\n",
      "Iteration 12600:\tloss: 0.027267064847576718\n",
      "Iteration 12700:\tloss: 0.026976869971889195\n",
      "Iteration 12800:\tloss: 0.02669432052725242\n",
      "Iteration 12900:\tloss: 0.026419020885106944\n",
      "----\n",
      " his isea test sentence for the sequence generationce for the sequence generationce for the sequence generationtence for the sequence generationtence for the sequence generationce for the sequence gene \n",
      "----\n",
      "Iteration 13000:\tloss: 0.026150605898513708\n",
      "Iteration 13100:\tloss: 0.025888738197904913\n",
      "Iteration 13200:\tloss: 0.025633105716123677\n",
      "Iteration 13300:\tloss: 0.025383419426316133\n",
      "Iteration 13400:\tloss: 0.025139411277709734\n",
      "----\n",
      " his is a test sentence for the sequence generation ence for the sequence generationsence for the sequence generationce for the sequence generationce for the sequence generationce for the sequence gene \n",
      "----\n",
      "Iteration 13500:\tloss: 0.024900832315290413\n",
      "Iteration 13600:\tloss: 0.02466745097002864\n",
      "Iteration 13700:\tloss: 0.024439051506741583\n",
      "Iteration 13800:\tloss: 0.024215432617045462\n",
      "Iteration 13900:\tloss: 0.023996406145239697\n",
      "----\n",
      " his is a test sentence for the sequence generationce for the sequence generationce for the sequence generationtence for the sequence generationce for the sequence generationce for the sequence generat \n",
      "----\n",
      "Iteration 14000:\tloss: 0.023781795935432976\n",
      "Iteration 14100:\tloss: 0.023571436788792526\n",
      "Iteration 14200:\tloss: 0.0233651735204692\n",
      "Iteration 14300:\tloss: 0.02316286010650036\n",
      "Iteration 14400:\tloss: 0.022964358911782435\n",
      "----\n",
      " his is a test sentence for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generationtence for the sequtnce sequence generationce for the sequenc \n",
      "----\n",
      "Iteration 14500:\tloss: 0.022769539991004305\n",
      "Iteration 14600:\tloss: 0.02257828045520433\n",
      "Iteration 14700:\tloss: 0.022390463897333495\n",
      "Iteration 14800:\tloss: 0.022205979870857442\n",
      "Iteration 14900:\tloss: 0.022024723416003138\n",
      "----\n",
      " his is a test sentence for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generation \n",
      "----\n",
      "Iteration 15000:\tloss: 0.021846594628748977\n",
      "Iteration 15100:\tloss: 0.02167149826807938\n",
      "Iteration 15200:\tloss: 0.021499343397378544\n",
      "Iteration 15300:\tloss: 0.02133004305614116\n",
      "Iteration 15400:\tloss: 0.02116351395843329\n",
      "----\n",
      " his is a test sentence for the sequence generationce for the sequence generationtence for the sequence generationce for the sequence generationce for the sequence generationtence for the sequence gene \n",
      "----\n",
      "Iteration 15500:\tloss: 0.020999676214759577\n",
      "Iteration 15600:\tloss: 0.020838453074187756\n",
      "Iteration 15700:\tloss: 0.020679770683757696\n",
      "Iteration 15800:\tloss: 0.020523557862365652\n",
      "Iteration 15900:\tloss: 0.020369745886475017\n",
      "----\n",
      " his is a test sentence fog the sequence generationce for the sequence generationce for the sequence generationce for the sequence generationtence for the sequence generationce for the sequence generat \n",
      "----\n",
      "Iteration 16000:\tloss: 0.02021826828517241\n",
      "Iteration 16100:\tloss: 0.02006906064228474\n",
      "Iteration 16200:\tloss: 0.019922060403522537\n",
      "Iteration 16300:\tloss: 0.01977720668697107\n",
      "Iteration 16400:\tloss: 0.01963444009577373\n",
      "----\n",
      " his is a test sentence for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generation \n",
      "----\n",
      "Iteration 16500:\tloss: 0.019493702532656722\n",
      "Iteration 16600:\tloss: 0.01935493701717437\n",
      "Iteration 16700:\tloss: 0.019218087508430973\n",
      "Iteration 16800:\tloss: 0.019083098738841425\n",
      "Iteration 16900:\tloss: 0.01894991606858613\n",
      "----\n",
      " his is a test sentence for the sequence generationce for the sequence generationce for the sequence generationtence for the sequence generationce for the sequence generationce for the sequence generat \n",
      "----\n",
      "Iteration 17000:\tloss: 0.018818485376179733\n",
      "Iteration 17100:\tloss: 0.018688753008300692\n",
      "Iteration 17200:\tloss: 0.018560665821660275\n",
      "Iteration 17300:\tloss: 0.01843417136031947\n",
      "Iteration 17400:\tloss: 0.01830921822097791\n",
      "----\n",
      " his is a test sentence for the sequence generationtence for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generat \n",
      "----\n",
      "Iteration 17500:\tloss: 0.018185756661287474\n",
      "Iteration 17600:\tloss: 0.01806373949395292\n",
      "Iteration 17700:\tloss: 0.017943123271840677\n",
      "Iteration 17800:\tloss: 0.01782386969825535\n",
      "Iteration 17900:\tloss: 0.01770594709485085\n",
      "----\n",
      " his is a test sentence for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generationtence for the sequence generat \n",
      "----\n",
      "Iteration 18000:\tloss: 0.017589331652303215\n",
      "Iteration 18100:\tloss: 0.017474008126300115\n",
      "Iteration 18200:\tloss: 0.017359969681865112\n",
      "Iteration 18300:\tloss: 0.017247216758398725\n",
      "Iteration 18400:\tloss: 0.017135755082410515\n",
      "----\n",
      " his is a test sentence for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generation \n",
      "----\n",
      "Iteration 18500:\tloss: 0.017025593188728753\n",
      "Iteration 18600:\tloss: 0.01691673991789451\n",
      "Iteration 18700:\tloss: 0.01680920230129027\n",
      "Iteration 18800:\tloss: 0.01670298407633047\n",
      "Iteration 18900:\tloss: 0.0165980848822805\n",
      "----\n",
      " his is a test sentence for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generation \n",
      "----\n",
      "Iteration 19000:\tloss: 0.016494500044551698\n",
      "Iteration 19100:\tloss: 0.01639222078679838\n",
      "Iteration 19200:\tloss: 0.016291234703599135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19300:\tloss: 0.016191526355308128\n",
      "Iteration 19400:\tloss: 0.01609307788712188\n",
      "----\n",
      " his is a test sentence for the sequence generationce for the sequence generationtence for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generat \n",
      "----\n",
      "Iteration 19500:\tloss: 0.015995869612116492\n",
      "Iteration 19600:\tloss: 0.01589988052704682\n",
      "Iteration 19700:\tloss: 0.015805088749351683\n",
      "Iteration 19800:\tloss: 0.015711471875704066\n",
      "Iteration 19900:\tloss: 0.015619007268784795\n",
      "----\n",
      " his is a test sentence for the sequence generationce for the sequence generationsence for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generat \n",
      "----\n",
      "Iteration 20000:\tloss: 0.01552767228169365\n",
      "Iteration 20100:\tloss: 0.015437444430009098\n",
      "Iteration 20200:\tloss: 0.015348301520957288\n",
      "Iteration 20300:\tloss: 0.015260221748069678\n",
      "Iteration 20400:\tloss: 0.015173183758459285\n",
      "----\n",
      " his is a test sentence for the sequence generationsence for the sequence generationce for the sequence generationtence for the sequence generationce for the sequence generationtence for the sequence g \n",
      "----\n",
      "Iteration 20500:\tloss: 0.015087166698623566\n",
      "Iteration 20600:\tloss: 0.015002150243578797\n",
      "Iteration 20700:\tloss: 0.014918114613182716\n",
      "Iteration 20800:\tloss: 0.014835040578710252\n",
      "Iteration 20900:\tloss: 0.014752909462099766\n",
      "----\n",
      " his is a test sentence for the sequence generationce for the sequence generationce for the seqtence sequence generationce for the sequence generationce for the sequence generationce for the sequence g \n",
      "----\n",
      "Iteration 21000:\tloss: 0.014671703129765522\n",
      "Iteration 21100:\tloss: 0.014591403982454936\n",
      "Iteration 21200:\tloss: 0.014511994942298809\n",
      "Iteration 21300:\tloss: 0.01443345943794182\n",
      "Iteration 21400:\tloss: 0.014355781388435792\n",
      "----\n",
      " his is a test sentence for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generation \n",
      "----\n",
      "Iteration 21500:\tloss: 0.014278945186417013\n",
      "Iteration 21600:\tloss: 0.014202935680963756\n",
      "Iteration 21700:\tloss: 0.014127738160431228\n",
      "Iteration 21800:\tloss: 0.014053338335484677\n",
      "Iteration 21900:\tloss: 0.013979722322492057\n",
      "----\n",
      " his is a test sentence for the sequence generationce for the sequence generationce for the sequence generationtence for the sequence generationsence for the generationce for the sequence generationsen \n",
      "----\n",
      "Iteration 22000:\tloss: 0.013906876627390553\n",
      "Iteration 22100:\tloss: 0.01383478813010604\n",
      "Iteration 22200:\tloss: 0.013763444069576216\n",
      "Iteration 22300:\tloss: 0.013692832029407121\n",
      "Iteration 22400:\tloss: 0.013622939924176165\n",
      "----\n",
      " his is a test sentence for the sequence generationeence for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generat \n",
      "----\n",
      "Iteration 22500:\tloss: 0.013553755986382672\n",
      "Iteration 22600:\tloss: 0.013485268754037546\n",
      "Iteration 22700:\tloss: 0.01341746705887675\n",
      "Iteration 22800:\tloss: 0.013350340015178494\n",
      "Iteration 22900:\tloss: 0.013283877009160481\n",
      "----\n",
      " his is a test sentence for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generation \n",
      "----\n",
      "Iteration 23000:\tloss: 0.013218067688931212\n",
      "Iteration 23100:\tloss: 0.013152901954967945\n",
      "Iteration 23200:\tloss: 0.013088369951093337\n",
      "Iteration 23300:\tloss: 0.013024462055922491\n",
      "Iteration 23400:\tloss: 0.01296116887475223\n",
      "----\n",
      " his is a test sentence for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generation \n",
      "----\n",
      "Iteration 23500:\tloss: 0.012898481231865247\n",
      "Iteration 23600:\tloss: 0.01283639016322233\n",
      "Iteration 23700:\tloss: 0.012774886909516864\n",
      "Iteration 23800:\tloss: 0.012713962909566773\n",
      "Iteration 23900:\tloss: 0.012653609794020441\n",
      "----\n",
      " his is a test sentence for the sequence generationce for the sequence generationce for the sequence generationsence for the sequence generationce for the sequence generationce for the sequence generat \n",
      "----\n",
      "Iteration 24000:\tloss: 0.012593819379353919\n",
      "Iteration 24100:\tloss: 0.012534583662138636\n",
      "Iteration 24200:\tloss: 0.012475894813559108\n",
      "Iteration 24300:\tloss: 0.012417745174162513\n",
      "Iteration 24400:\tloss: 0.012360127248822073\n",
      "----\n",
      " his is a test sentence for the sequence generation ence for the sequence generationce for the sequence generationce for the sequence generationtence for the sequence generationce for the sequence gene \n",
      "----\n",
      "Iteration 24500:\tloss: 0.01230303370189852\n",
      "Iteration 24600:\tloss: 0.012246457352584292\n",
      "Iteration 24700:\tloss: 0.012190391170416686\n",
      "Iteration 24800:\tloss: 0.012134828270947206\n",
      "Iteration 24900:\tloss: 0.012079761911555676\n",
      "----\n",
      " his is a test sentence for the sequence generationce for the sequence generationsence for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generat \n",
      "----\n",
      "Iteration 25000:\tloss: 0.012025185487398503\n",
      "Iteration 25100:\tloss: 0.011971092527481589\n",
      "Iteration 25200:\tloss: 0.011917476690849615\n",
      "Iteration 25300:\tloss: 0.011864331762884069\n",
      "Iteration 25400:\tloss: 0.011811651651703487\n",
      "----\n",
      " his is a test sentence for the sequence generationce for the sequence generationtence for the sequence generationtence for the sequence generationsence for the sequence generationce for the sequence g \n",
      "----\n",
      "Iteration 25500:\tloss: 0.011759430384660392\n",
      "Iteration 25600:\tloss: 0.011707662104929647\n",
      "Iteration 25700:\tloss: 0.01165634106818463\n",
      "Iteration 25800:\tloss: 0.011605461639357335\n",
      "Iteration 25900:\tloss: 0.011555018289479928\n",
      "----\n",
      " his is a test sentence for the sequence generationce for the sequence generationce for the sequence generationtence for the sequence generationce for the sequence generationce for the sequence generat \n",
      "----\n",
      "Iteration 26000:\tloss: 0.011505005592605588\n",
      "Iteration 26100:\tloss: 0.01145541822280663\n",
      "Iteration 26200:\tloss: 0.011406250951249286\n",
      "Iteration 26300:\tloss: 0.01135749864334378\n",
      "Iteration 26400:\tloss: 0.011309156255969618\n",
      "----\n",
      " his is a test sentence for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generationsence for the sequence generat \n",
      "----\n",
      "Iteration 26500:\tloss: 0.011261218834775646\n",
      "Iteration 26600:\tloss: 0.011213681511555182\n",
      "Iteration 26700:\tloss: 0.011166539501696104\n",
      "Iteration 26800:\tloss: 0.011119788101706506\n",
      "Iteration 26900:\tloss: 0.011073422686815833\n",
      "----\n",
      " his is a test sentence for the sequence generationsence for the sequence generationce for the sequence generationce for the sequence generationtence for the sequence generationce for the sequence gene \n",
      "----\n",
      "Iteration 27000:\tloss: 0.011027438708652366\n",
      "Iteration 27100:\tloss: 0.010981831692996895\n",
      "Iteration 27200:\tloss: 0.010936597237613078\n",
      "Iteration 27300:\tloss: 0.010891731010154459\n",
      "Iteration 27400:\tloss: 0.010847228746148256\n",
      "----\n",
      " his is a test sentence for the sequence generationsence for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generat \n",
      "----\n",
      "Iteration 27500:\tloss: 0.010803086247055498\n",
      "Iteration 27600:\tloss: 0.010759299378407501\n",
      "Iteration 27700:\tloss: 0.010715864068017708\n",
      "Iteration 27800:\tloss: 0.010672776304268397\n",
      "Iteration 27900:\tloss: 0.010630032134471197\n",
      "----\n",
      " his is a test sentence for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generation \n",
      "----\n",
      "Iteration 28000:\tloss: 0.010587627663300231\n",
      "Iteration 28100:\tloss: 0.0105455590512964\n",
      "Iteration 28200:\tloss: 0.010503822513441492\n",
      "Iteration 28300:\tloss: 0.010462414317799984\n",
      "Iteration 28400:\tloss: 0.010421330784226931\n",
      "----\n",
      " his is a test sentence for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generationce sentence for the sequence generationsence for the sequenc \n",
      "----\n",
      "Iteration 28500:\tloss: 0.010380568283139678\n",
      "Iteration 28600:\tloss: 0.010340123234351217\n",
      "Iteration 28700:\tloss: 0.010299992105962767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 28800:\tloss: 0.010260171413313323\n",
      "Iteration 28900:\tloss: 0.01022065771798347\n",
      "----\n",
      " his is a test sentence for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generationsence for the sequence generationtence for the sequence gene \n",
      "----\n",
      "Iteration 29000:\tloss: 0.010181447626850946\n",
      "Iteration 29100:\tloss: 0.010142537791195365\n",
      "Iteration 29200:\tloss: 0.010103924905849427\n",
      "Iteration 29300:\tloss: 0.01006560570839398\n",
      "Iteration 29400:\tloss: 0.010027576978394306\n",
      "----\n",
      " his is a test sentence for the sequence generationce for the sequence generationce for the sequence generationsence for the sequence generationce for the sequence generationce for the sequence generat \n",
      "----\n",
      "Iteration 29500:\tloss: 0.009989835536675071\n",
      "Iteration 29600:\tloss: 0.009952378244631339\n",
      "Iteration 29700:\tloss: 0.00991520200357318\n",
      "Iteration 29800:\tloss: 0.00987830375410136\n",
      "Iteration 29900:\tloss: 0.009841680475512073\n",
      "----\n",
      " his is a test sentence for the sequence generationce for the sequence generationce for the sequence generationce for the sequence generationsence for the sequence generationce for the sequence generat \n",
      "----\n",
      "Iteration 30000:\tloss: 0.009805329185228024\n"
     ]
    }
   ],
   "source": [
    "n, p = 0, 0\n",
    "mWxh, mWhh, mWhy =  np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why) # memory vars for AdaGrad\n",
    "mbh, mby = np.zeros_like(bh), np.zeros_like(by)\n",
    "smooth_loss = -np.log(1.0/vocab_size) * seq_length # loss at iteration 0\n",
    "\n",
    "while n < 30001:\n",
    "    if p+seq_length+1 >= len(data) or n == 0: # sliding window of size seq_length: sweeping from left to right \n",
    "        hprev = np.zeros((hidden_size, 1)) # reset RNN memory\n",
    "        p = 0 \n",
    "    inputs = [char_to_ix[ch] for ch in data[p : p+seq_length]]\n",
    "    targets = [char_to_ix[ch] for ch in data[p+1 : p+seq_length+1]]\n",
    "    \n",
    "    if n % 500 == 0:\n",
    "        sample_ix = sample(hprev, inputs[0], 200)\n",
    "        txt = ''.join(ix_to_char[ix] for ix in sample_ix)\n",
    "        print(\"----\\n {0} \\n----\".format(txt))\n",
    "        \n",
    "    # forward seq_length chars through the RNN and fetch gradients\n",
    "    loss, dWxh, dWhh, dWhy, dbh, dby, hprev = loss_func(inputs, targets, hprev)\n",
    "    smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
    "    if n % 100 == 0:\n",
    "        print(\"Iteration {0}:\\tloss: {1}\".format(n, smooth_loss))\n",
    "        \n",
    "    # AdaGrad for parameter update\n",
    "    for param, dparam, mem in zip([Wxh, Whh, Why, bh, by], [dWxh, dWhh, dWhy, dbh, dby], \n",
    "                                  [mWxh, mWhh, mWhy, mbh, mby]):\n",
    "        mem += dparam * dparam\n",
    "        param += -learning_rate * dparam / np.sqrt(mem + 1e-8)\n",
    "        \n",
    "    p += seq_length # move the data point\n",
    "    n += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
